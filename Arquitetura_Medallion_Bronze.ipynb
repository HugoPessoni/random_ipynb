{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Arquitetura Medallion\n",
        "A Arquitetura Medallion é uma abordagem para construir um Data Warehouse ou Data Lake focada em qualidade, confiabilidade e acessibilidade dos dados. Ela organiza os dados em camadas com níveis crescentes de refinamento, estrutura e valor de negócio, similar a um processo de lapidação de um diamante bruto até uma joia polida e valiosa.\n",
        "\n",
        "As camadas da Arquitetura Medallion são:\n",
        "\n",
        "1. Bronze (Bruta):\n",
        "\n",
        "* Objetivo: armazenar os dados brutos, exatamente como foram capturados das fontes originais, sem qualquer transformação ou limpeza.\n",
        "* Formato: arquivos no formato original (CSV, JSON, XML, etc.), geralmente armazenados em um Data Lake (e.g., HDFS, S3).\n",
        "* Características:\n",
        "  * Dados brutos e não processados.\n",
        "  * Schema-on-read (o esquema é inferido quando os dados são lidos).\n",
        "  * Alta variedade e volume de dados.\n",
        "  * Baixa latência de ingestão (dados são disponibilizados rapidamente).\n",
        "  * Exemplo: logs de aplicação, feeds de dados de sensores, dados de redes sociais.\n",
        "\n",
        "2. Silver (Aprimorada):\n",
        "\n",
        "* Objetivo: limpar, transformar e enriquecer os dados brutos da camada Bronze.\n",
        "* Formato: dados estruturados em formatos como Parquet ou ORC, armazenados em um Data Lake ou Data Warehouse.\n",
        "* Características:\n",
        "  * Dados limpos, consistentes e com maior qualidade.\n",
        "  * Schema-on-write (o esquema é definido antes da escrita dos dados).\n",
        "  * Dados desduplicados e com valores nulos tratados.\n",
        "  * Adição de informações contextuais e enriquecimento dos dados.\n",
        "  * Exemplo: dados de clientes com informações demográficas unificadas e padronizadas, dados de vendas com informações de produtos e promoções.\n",
        "3. Gold (Refinada):\n",
        "\n",
        "* Objetivo: criar datasets agregados e otimizados para análises de negócios e tomada de decisão.\n",
        "* Formato: tabelas dimensionais e fatos, armazenadas em um Data Warehouse, Data Marts ou agregados pré-calculados para dashboards.\n",
        "* Características:\n",
        "  * Dados altamente estruturados e organizados para atender às necessidades específicas de negócio.\n",
        "  * Dados históricos e dados atuais consolidados.\n",
        "  * Dados otimizados para performance em consultas analíticas.\n",
        "  * Alta qualidade e confiabilidade dos dados.\n",
        "  * Exemplo: tabelas de dimensão de tempo, cliente e produto, tabelas de fatos de vendas, indicadores chave de performance (KPIs) pré-calculados.\n",
        "\n",
        "Benefícios da Arquitetura Medallion:\n",
        "\n",
        "* Escalabilidade e flexibilidade: permite lidar com grandes volumes e variedade de dados.\n",
        "* Qualidade e confiabilidade dos dados: assegura a qualidade dos dados através de um processo incremental de refinamento.\n",
        "* Agilidade: facilita a ingestão e processamento de novos dados.\n",
        "* Reutilização de dados: permite que os mesmos dados brutos sejam utilizados para diferentes propósitos.\n",
        "* Governança de dados: facilita a gestão e controle dos dados em cada camada.\n",
        "\n",
        "![medallion-architecture](https://miro.medium.com/v2/resize:fit:1400/1*O4ey_K0ZbsESf8na7OirJg.jpeg)\n"
      ],
      "metadata": {
        "id": "_NCGbNGg5jml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download dos arquivos\n",
        "\n",
        "Iremos baixar os arquivos de entrada:\n",
        "- clients.csv\n",
        "- vendas.csv\n",
        "\n",
        "Os dados em `vendas.csv` são relativos a vendas realizadas por atacadistas e distribuidores."
      ],
      "metadata": {
        "id": "wZNyqh8F8Yz4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dados de clientes\n",
        "\n",
        "Iremos realizar o download de dados de clientes do link abaixo:"
      ],
      "metadata": {
        "id": "xNZitw1TEPTY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVJyy_fUNNyW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "700188f4-b4ab-4919-ba85-7c4d57aeb0de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-17 13:04:49--  https://www.dropbox.com/scl/fi/vd5hmlr7ghj2j5rx3w681/clients.csv?rlkey=rmcalhytfjm6nfklw7hhtykid\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucd0e62c71b03ebea233712f93b1.dl.dropboxusercontent.com/cd/0/inline/CcmoP4of6k0xj1T5czLyZz_HTbxlktzZUJYM9j0EHMhjwD6GD3L4WO_2ZFV5OoYtSNpPX4wpkNcfZjw6IlVfsVrjS5LG4wxFc8gm0TwKg_CHqSv3jEvjQ7rfBre8j6faQsJXJ9jYzfJu6ttGNZDZ_9PT/file# [following]\n",
            "--2024-10-17 13:04:50--  https://ucd0e62c71b03ebea233712f93b1.dl.dropboxusercontent.com/cd/0/inline/CcmoP4of6k0xj1T5czLyZz_HTbxlktzZUJYM9j0EHMhjwD6GD3L4WO_2ZFV5OoYtSNpPX4wpkNcfZjw6IlVfsVrjS5LG4wxFc8gm0TwKg_CHqSv3jEvjQ7rfBre8j6faQsJXJ9jYzfJu6ttGNZDZ_9PT/file\n",
            "Resolving ucd0e62c71b03ebea233712f93b1.dl.dropboxusercontent.com (ucd0e62c71b03ebea233712f93b1.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to ucd0e62c71b03ebea233712f93b1.dl.dropboxusercontent.com (ucd0e62c71b03ebea233712f93b1.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42358668 (40M) [text/plain]\n",
            "Saving to: ‘clients.csv’\n",
            "\n",
            "clients.csv         100%[===================>]  40.40M  62.9MB/s    in 0.6s    \n",
            "\n",
            "2024-10-17 13:04:51 (62.9 MB/s) - ‘clients.csv’ saved [42358668/42358668]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O clients.csv https://www.dropbox.com/scl/fi/vd5hmlr7ghj2j5rx3w681/clients.csv?rlkey=rmcalhytfjm6nfklw7hhtykid&dl=1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Se não funcionar o download acima, tente o link abaixo:**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "R-PhnPvyCnZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!gdown https://drive.google.com/uc?id=1SQn8nCPhdFXFOe2wZ9wn1exTAIdgo2QU"
      ],
      "metadata": {
        "id": "oInJIJszCryu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dados de vendas\n",
        "\n",
        "Iremos realizar o download dos dados de vendas presentes no arquivo `vendas.csv`:"
      ],
      "metadata": {
        "id": "Grs7LvgUEXbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O vendas.csv https://www.dropbox.com/scl/fi/y6h3do8rp9fhovunvj36c/vendas.csv?rlkey=m4yl4h8vzfyg5fq8vyb2sbd2x&st=nz4dme6m&dl=1"
      ],
      "metadata": {
        "id": "XKdikSZa7GNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c41e18c4-4ff2-4e27-fc9f-e49e37817616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-17 13:04:51--  https://www.dropbox.com/scl/fi/y6h3do8rp9fhovunvj36c/vendas.csv?rlkey=m4yl4h8vzfyg5fq8vyb2sbd2x\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc65c500c14094064ee0831750ba.dl.dropboxusercontent.com/cd/0/inline/CckfKHR2w_q5wc1ZwVvsLmOSIugydWx86Eg0OOf6syzIckXtTf41IUR-SuwbPFkdBunmMJfwope9IdH-VovPfJtjbgF4mn_blux1_duUFiy5CmHCcfEGp6MmpO2fOgfgTj53aObcYbr9EP9q0OmmjYa9/file# [following]\n",
            "--2024-10-17 13:04:52--  https://uc65c500c14094064ee0831750ba.dl.dropboxusercontent.com/cd/0/inline/CckfKHR2w_q5wc1ZwVvsLmOSIugydWx86Eg0OOf6syzIckXtTf41IUR-SuwbPFkdBunmMJfwope9IdH-VovPfJtjbgF4mn_blux1_duUFiy5CmHCcfEGp6MmpO2fOgfgTj53aObcYbr9EP9q0OmmjYa9/file\n",
            "Resolving uc65c500c14094064ee0831750ba.dl.dropboxusercontent.com (uc65c500c14094064ee0831750ba.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc65c500c14094064ee0831750ba.dl.dropboxusercontent.com (uc65c500c14094064ee0831750ba.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36215113 (35M) [text/plain]\n",
            "Saving to: ‘vendas.csv’\n",
            "\n",
            "vendas.csv          100%[===================>]  34.54M  51.0MB/s    in 0.7s    \n",
            "\n",
            "2024-10-17 13:04:53 (51.0 MB/s) - ‘vendas.csv’ saved [36215113/36215113]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Se não funcionar o download acima, tente o link abaixo:**"
      ],
      "metadata": {
        "id": "WpYgkXP3DLTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!gdown https://drive.google.com/uc?id=1ubiLTdjEdy8C86MdkW1HRyPOFZl4irT1"
      ],
      "metadata": {
        "id": "vAREVqLIDPXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analisando dados de vendas\n",
        "Você está recebendo um conjunto de dados histórico de vendas de ERPs de várias empresas. Temos o histórico de vendas de várias empresas dentro do arquivo e, por isso, podemos ter períodos históricos diferentes de dados de vendas disponíveis.\n",
        "\n",
        "## Arquivos\n",
        "- **vendas.csv** - contém dados históricos de vendas até junho de 2022.\n",
        "- **clients.csv** - dados dos clientes que compraram o produto.\n",
        "\n",
        "## Campos do arquivo de vendas\n",
        "\n",
        "- *client_id*: id do cliente.\n",
        "- *items_count*: número de itens vendidos\n",
        "- *list_price*: preço do produto no catálogo da empresa.\n",
        "- *order_date*: data da venda.\n",
        "- *order_id*: id do pedido. Cada pedido pode conter vários produtos vendidos dentro dele.\n",
        "- *product_id*: id do produto vendido.\n",
        "- *sale_price*: preço vendido ao cliente.\n",
        "- *salesman_id*: id do vendedor.\n",
        "- *supplier_id*: id do fornecedor do produto. Por exemplo, a indústria fabricando do produto.\n",
        "- *company_id*: id da empresa. Temos dentro da base o histórico de vendas de várias empresas para clientes finais.\n",
        "- *product*: nome do produto.\n",
        "- *salesman*: nome do vendedor.\n",
        "- *supplier*: nome do fornecedor.\n",
        "- *client*: nome do cliente.\n",
        "\n",
        "\n",
        "## Campos do arquivo clients.csv\n",
        "- *client_id*: id do cliente.\n",
        "- *cnae_id*: CNAE do cliente que está realizando a compra.\n",
        "- *cod_city*: código da cidade no IBGE em que o cliente está localizado.\n",
        "- *cod_tract*: código do setor censitário no IBGE em que o cliente está localizado.\n",
        "- *cod_uf*: código da UF no IBGE em que o cliente está localizado.\n",
        "- *city*: cidade do cliente.\n",
        "- *state*: UF do cliente.\n",
        "- *client*: nome do cliente.\n",
        "- *company_id*: id da empresa. Temos dentro da base o histórico de vendas de várias empresas para clientes finais.\n"
      ],
      "metadata": {
        "id": "byQsilyGtLLJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ts2iqOfStVG"
      },
      "source": [
        "## Iniciando o PySpark\n",
        "\n",
        "Esta célula de código instala o Spark no ambiente de execução Colab. Aqui está uma explicação passo a passo:\n",
        "\n",
        "1. **`!apt-get install openjdk-11-jdk-headless -qq > /dev/null`**: este comando instala o OpenJDK 11 (versão headless, sem interface gráfica), que é um requisito para o Spark. O `-qq` suprime a saída e o `> /dev/null` redireciona a saída para o nada, tornando o processo mais silencioso.\n",
        "\n",
        "2. **`!wget -q https://dlcdn.apache.org/spark/spark-3.5.2/spark-3.5.2-bin-hadoop3.tgz`**: Este comando baixa o arquivo compactado do Spark 3.5.2 (construído para o Hadoop 3) do site oficial do Apache Spark. O `-q` suprime a saída de download.\n",
        "\n",
        "3. **`!tar xf spark-3.5.2-bin-hadoop3.tgz`**: Este comando extrai o arquivo compactado baixado do Spark, criando um diretório chamado `spark-3.5.2-bin-hadoop3`.\n",
        "\n",
        "4. **`!pip -q install findspark`**: Este comando instala a biblioteca `findspark` usando `pip`. Findspark é uma biblioteca Python que torna mais fácil configurar o Spark em um ambiente Python, principalmente no Colab. Ela define as variáveis de ambiente necessárias para que o Spark funcione corretamente.\n",
        "\n",
        "Após executar essas linhas, você terá o Spark instalado e pronto para ser usado em seu notebook Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ek_RTaPXSwLp"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.5.2/spark-3.5.2-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.2-bin-hadoop3.tgz\n",
        "!pip -q install findspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defina as variáveis de ambiente do Spark:"
      ],
      "metadata": {
        "id": "duVQdGSXo1fS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qM3oCEa4Sx1g"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.2-bin-hadoop3\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código a seguir garante que o Spark seja configurado corretamente e esteja pronto para uso em seu ambiente Python.\n",
        "\n",
        "* **`findspark.init()`**: executa a função `init()` do módulo `findspark`. Esta função:\n",
        "    * Localiza a instalação do Spark em seu sistema.\n",
        "    * Configura as variáveis de ambiente necessárias para que o Python possa interagir com o Spark. Isso permite que o driver Python (seu código Python) se comunique com o executor Spark (o código que realmente processa os dados).\n"
      ],
      "metadata": {
        "id": "QV6xIUNwo2KZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgkpQMC6S0SE"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depois de executar a célula anterior, você poderá importar e usar as bibliotecas Spark como `pyspark.sql.SparkSession` para criar uma sessão Spark e começar a trabalhar com dados."
      ],
      "metadata": {
        "id": "WMUFJ_Bto5BJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAhdigi7S04j"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "spark = SparkSession.builder.appName('Aula 1').master(\"local[*]\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRw-e1pRT9qD"
      },
      "source": [
        "# Primeira etapa: carregar os arquivos\n",
        "\n",
        "Nessa etapa você deve carregar os quatro arquivos abaixos, utilizando o **Spark**\n",
        "\n",
        "**Dicas:**\n",
        "\n",
        "- Separador dos arquivos é , (vírgula)\n",
        "- Os arquivos possuem cabeçalho"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clients_df = spark.read.csv(\"clients.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "gSa8umScM6NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clients_df.show()"
      ],
      "metadata": {
        "id": "C2eQZ6FmNvqz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e6eda5a-0475-48d0-ee66-099d3c6afad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+-------+--------+---------------+------+-----+--------------+----------+\n",
            "|                city|client_id|cnae_id|cod_city|      cod_tract|cod_uf|state|        client|company_id|\n",
            "+--------------------+---------+-------+--------+---------------+------+-----+--------------+----------+\n",
            "|                NULL|  c855767|   NULL| 5211503|521150305000094|    52|   GO|Client c855767|       567|\n",
            "|               POSSE|  c836888|   NULL| 5218300|521830005000006|    52|   GO|Client c836888|       567|\n",
            "|                 POA|  c836597|   NULL| 3539806|353980605000005|    35|   SP|Client c836597|       567|\n",
            "|           SAO PAULO|  c836596|   NULL| 3550308|355030837000019|    35|   SP|Client c836596|       567|\n",
            "|              CUIABA|  c855005|   NULL| 5103403|510340310400031|    51|   MT|Client c855005|       567|\n",
            "|         BREU BRANCO|  c855045|   NULL| 1501782|150178205000045|    15|   PA|Client c855045|       567|\n",
            "|APARECIDA DE GOIANIA|  c836630|   NULL| 5201405|520140505000019|    52|   GO|Client c836630|       567|\n",
            "|      PEDRAS MA CRUZ|  c904501|   NULL| 3149150|314915005000003|    31|   MG|Client c904501|       567|\n",
            "|            JANUARIA|  c903627|   NULL| 3135209|313520905000021|    31|   MG|Client c903627|       567|\n",
            "|        RONDONOPOLIS|  c903616|   NULL| 5107602|510760205000190|    51|   MT|Client c903616|       567|\n",
            "|             JANAUBA|  c903671|   NULL| 3135100|313510005000048|    31|   MG|Client c903671|       567|\n",
            "|             GOIANIA|  c903669|   NULL| 5208707|520870705020011|    52|   GO|Client c903669|       567|\n",
            "|      PATOS DE MINAS|  c903656|   NULL| 3148004|314800405000184|    31|   MG|Client c903656|       567|\n",
            "|         SAO GOTARDO|  c903643|   NULL| 3162104|316210415000001|    31|   MG|Client c903643|       567|\n",
            "|        PORTO FRANCO|  c903694|   NULL| 2109007|210900705000023|    21|   MA|Client c903694|       567|\n",
            "|        PORTO FRANCO|  c903693|   NULL| 2109007|210900705000023|    21|   MA|Client c903693|       567|\n",
            "|        PORTO FRANCO|  c903692|   NULL| 2109007|210900705000008|    21|   MA|Client c903692|       567|\n",
            "|             GOIANIA|  c903681|   NULL| 5208707|520870705090001|    52|   GO|Client c903681|       567|\n",
            "|     SAO FELIX XINGU|  c903751|   NULL| 1507300|150730005000010|    15|   PA|Client c903751|       567|\n",
            "|        RONDONOPOLIS|  c903715|   NULL| 5107602|510760205000022|    51|   MT|Client c903715|       567|\n",
            "+--------------------+---------+-------+--------+---------------+------+-----+--------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clients_df.printSchema()"
      ],
      "metadata": {
        "id": "eH1zh5moNerl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d57c73fd-00a1-49c2-fb9b-f06fed1687a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- city: string (nullable = true)\n",
            " |-- client_id: string (nullable = true)\n",
            " |-- cnae_id: string (nullable = true)\n",
            " |-- cod_city: integer (nullable = true)\n",
            " |-- cod_tract: long (nullable = true)\n",
            " |-- cod_uf: integer (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- client: string (nullable = true)\n",
            " |-- company_id: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzsaH61tUH6b"
      },
      "outputs": [],
      "source": [
        "clients_schema = \"city string, client_id string, cnae_id string, \\\n",
        "cod_city integer, cod_tract long, cod_uf integer, state string, client string, \\\n",
        " company_id integer\"\n",
        "clients_df = spark.read.csv(\"clients.csv\", header=True, schema=clients_schema, mode=\"DROPMALFORMED\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vendas_df = spark.read.csv(\"vendas.csv\",header=True)"
      ],
      "metadata": {
        "id": "U7yMcAkXXlKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFpp2lmlUT8A"
      },
      "outputs": [],
      "source": [
        "vendas_schema = \"client_id string, items_count integer, list_price float, \\\n",
        "order_date date, order_id integer, product_id string, sale_price float, \\\n",
        "salesman_id string, supplier_id string, company_id integer, product string, \\\n",
        "salesman string, supplier string, client string\"\n",
        "vendas_df = spark.read.csv(\"vendas.csv\",header=True, schema=vendas_schema)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vendas_df.printSchema()"
      ],
      "metadata": {
        "id": "2CXctYolWiYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd1e1d0-cdb7-453f-f680-ebc8d0ecfae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- client_id: string (nullable = true)\n",
            " |-- items_count: integer (nullable = true)\n",
            " |-- list_price: float (nullable = true)\n",
            " |-- order_date: date (nullable = true)\n",
            " |-- order_id: integer (nullable = true)\n",
            " |-- product_id: string (nullable = true)\n",
            " |-- sale_price: float (nullable = true)\n",
            " |-- salesman_id: string (nullable = true)\n",
            " |-- supplier_id: string (nullable = true)\n",
            " |-- company_id: integer (nullable = true)\n",
            " |-- product: string (nullable = true)\n",
            " |-- salesman: string (nullable = true)\n",
            " |-- supplier: string (nullable = true)\n",
            " |-- client: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbeJjvp3X7jQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25af1a32-bf15-4716-c570-60d50a2fa980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+-------+--------+---------------+------+-----+--------------+----------+\n",
            "|                city|client_id|cnae_id|cod_city|      cod_tract|cod_uf|state|        client|company_id|\n",
            "+--------------------+---------+-------+--------+---------------+------+-----+--------------+----------+\n",
            "|                NULL|  c855767|   NULL| 5211503|521150305000094|    52|   GO|Client c855767|       567|\n",
            "|               POSSE|  c836888|   NULL| 5218300|521830005000006|    52|   GO|Client c836888|       567|\n",
            "|                 POA|  c836597|   NULL| 3539806|353980605000005|    35|   SP|Client c836597|       567|\n",
            "|           SAO PAULO|  c836596|   NULL| 3550308|355030837000019|    35|   SP|Client c836596|       567|\n",
            "|              CUIABA|  c855005|   NULL| 5103403|510340310400031|    51|   MT|Client c855005|       567|\n",
            "|         BREU BRANCO|  c855045|   NULL| 1501782|150178205000045|    15|   PA|Client c855045|       567|\n",
            "|APARECIDA DE GOIANIA|  c836630|   NULL| 5201405|520140505000019|    52|   GO|Client c836630|       567|\n",
            "|      PEDRAS MA CRUZ|  c904501|   NULL| 3149150|314915005000003|    31|   MG|Client c904501|       567|\n",
            "|            JANUARIA|  c903627|   NULL| 3135209|313520905000021|    31|   MG|Client c903627|       567|\n",
            "|        RONDONOPOLIS|  c903616|   NULL| 5107602|510760205000190|    51|   MT|Client c903616|       567|\n",
            "|             JANAUBA|  c903671|   NULL| 3135100|313510005000048|    31|   MG|Client c903671|       567|\n",
            "|             GOIANIA|  c903669|   NULL| 5208707|520870705020011|    52|   GO|Client c903669|       567|\n",
            "|      PATOS DE MINAS|  c903656|   NULL| 3148004|314800405000184|    31|   MG|Client c903656|       567|\n",
            "|         SAO GOTARDO|  c903643|   NULL| 3162104|316210415000001|    31|   MG|Client c903643|       567|\n",
            "|        PORTO FRANCO|  c903694|   NULL| 2109007|210900705000023|    21|   MA|Client c903694|       567|\n",
            "|        PORTO FRANCO|  c903693|   NULL| 2109007|210900705000023|    21|   MA|Client c903693|       567|\n",
            "|        PORTO FRANCO|  c903692|   NULL| 2109007|210900705000008|    21|   MA|Client c903692|       567|\n",
            "|             GOIANIA|  c903681|   NULL| 5208707|520870705090001|    52|   GO|Client c903681|       567|\n",
            "|     SAO FELIX XINGU|  c903751|   NULL| 1507300|150730005000010|    15|   PA|Client c903751|       567|\n",
            "|        RONDONOPOLIS|  c903715|   NULL| 5107602|510760205000022|    51|   MT|Client c903715|       567|\n",
            "+--------------------+---------+-------+--------+---------------+------+-----+--------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clients_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vendas_df.show()"
      ],
      "metadata": {
        "id": "QyeGXccNX6Xf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa4f070a-2ade-4773-9a3c-2dbd9946a78b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+----------+----------+--------+----------+----------+-----------+-----------+----------+-------------+------------+-------------+------------+\n",
            "|client_id|items_count|list_price|order_date|order_id|product_id|sale_price|salesman_id|supplier_id|company_id|      product|    salesman|     supplier|      client|\n",
            "+---------+-----------+----------+----------+--------+----------+----------+-----------+-----------+----------+-------------+------------+-------------+------------+\n",
            "|    c2943|          3|       0.0|2020-05-21|    NULL|     p1477| 25.166666|        s69|       su28|       603|Product p1477|Salesman s69|Supplier su28|Client c2943|\n",
            "|    c2943|         12|       0.0|2020-05-21|    NULL|      p156|   19.4653|        s69|       su16|       603| Product p156|Salesman s69|Supplier su16|Client c2943|\n",
            "|    c2092|          2|       0.0|2020-05-21|    NULL|     p1314|    39.985|        s19|       su16|       603|Product p1314|Salesman s19|Supplier su16|Client c2092|\n",
            "|    c3412|          5|       0.0|2020-05-18|    NULL|      p272|     26.25|        s79|       su19|       603| Product p272|Salesman s79|Supplier su19|Client c3412|\n",
            "|    c3412|         10|       0.0|2020-05-18|    NULL|      p339|     13.68|        s79|       su19|       603| Product p339|Salesman s79|Supplier su19|Client c3412|\n",
            "|    c3412|         20|       0.0|2020-05-18|    NULL|      p480|      4.02|        s79|       su19|       603| Product p480|Salesman s79|Supplier su19|Client c3412|\n",
            "|    c4073|          3|       0.0|2020-05-18|    NULL|      p359|       5.7|        s81|       su19|       603| Product p359|Salesman s81|Supplier su19|Client c4073|\n",
            "|    c4073|          5|       0.0|2020-05-18|    NULL|      p361|       5.7|        s81|       su19|       603| Product p361|Salesman s81|Supplier su19|Client c4073|\n",
            "|    c4073|          2|       0.0|2020-05-18|    NULL|      p362|       5.7|        s81|       su19|       603| Product p362|Salesman s81|Supplier su19|Client c4073|\n",
            "|    c4073|          1|       0.0|2020-05-18|    NULL|      p469|       6.8|        s81|       su19|       603| Product p469|Salesman s81|Supplier su19|Client c4073|\n",
            "|    c4073|          2|       0.0|2020-05-18|    NULL|     p1280|      3.74|        s81|       su19|       603|Product p1280|Salesman s81|Supplier su19|Client c4073|\n",
            "|    c3305|          6|       0.0|2020-05-18|    NULL|      p485|      5.95|        s79|       su19|       603| Product p485|Salesman s79|Supplier su19|Client c3305|\n",
            "|     c355|         12|       0.0|2020-05-18|    NULL|      p485| 6.2716665|        s12|       su19|       603| Product p485|Salesman s12|Supplier su19| Client c355|\n",
            "|    c4848|         40|       0.0|2020-05-18|    NULL|      p576|      2.54|        s25|       su19|       603| Product p576|Salesman s25|Supplier su19|Client c4848|\n",
            "|     c269|          1|       0.0|2020-05-18|    NULL|      p373|     14.01|        s12|       su19|       603| Product p373|Salesman s12|Supplier su19| Client c269|\n",
            "|    c4854|        100|       0.0|2020-05-18|    NULL|      p433|      0.58|        s81|       su19|       603| Product p433|Salesman s81|Supplier su19|Client c4854|\n",
            "|    c1692|          2|       0.0|2020-05-18|    NULL|      p234|      10.0|        s59|       su19|       603| Product p234|Salesman s59|Supplier su19|Client c1692|\n",
            "|    c1692|          2|       0.0|2020-05-18|    NULL|      p486|      22.4|        s59|       su19|       603| Product p486|Salesman s59|Supplier su19|Client c1692|\n",
            "|    c1692|         10|       0.0|2020-05-18|    NULL|      p340|      8.84|        s59|       su19|       603| Product p340|Salesman s59|Supplier su19|Client c1692|\n",
            "|    c1692|         50|       0.0|2020-05-18|    NULL|     p2239|      1.31|        s59|       su19|       603|Product p2239|Salesman s59|Supplier su19|Client c1692|\n",
            "+---------+-----------+----------+----------+--------+----------+----------+-----------+-----------+----------+-------------+------------+-------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spark Pandas\n",
        "\n",
        "### O que é Spark Pandas?\n",
        "\n",
        "Spark Pandas é uma biblioteca que fornece uma interface similar ao Pandas para trabalhar com dados em clusters Apache Spark. Isso significa que você pode usar as mesmas funções e métodos do Pandas, mas com a capacidade de processar datasets imensos distribuídos em vários nós.\n",
        "\n",
        "### Por que usar Spark Pandas?\n",
        "\n",
        "Para cientistas de dados, o Spark Pandas oferece diversas vantagens:\n",
        "\n",
        "- Escalabilidade: processa conjuntos de dados enormes com rapidez e eficiência, utilizando a computação distribuída do Spark.\n",
        "- Familiaridade: permite utilizar a linguagem e as funções do Pandas, que você já conhece, para análise de dados em grande escala.\n",
        "- Performance: aproveita as otimizações do Spark para acelerar tarefas como leitura, transformação e agregação de dados.\n",
        "- Integração: funciona perfeitamente com outros componentes do ecossistema Spark, como Spark SQL e MLlib."
      ],
      "metadata": {
        "id": "D3KMk5UC7Ey3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vamos fazer a mesma operação de leitura de dados de clientes e vendas com **Spark Pandas** (vide [documentação](https://spark.apache.org/docs/latest/api/python/user_guide/pandas_on_spark/index.html)).\n",
        "\n",
        "Os clientes vamos armazenar no Dataframe `clients_pdf` e os dados de vendas em `vendas_pdf`. A leitura do csv é semelhante ao Pandas com o método `read_csv`."
      ],
      "metadata": {
        "id": "Sx-MIEKB7K_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.pandas as ps"
      ],
      "metadata": {
        "id": "UkjV-kl37VMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84629ea2-8f4d-4e0c-df25-822eec5c88ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/spark-3.5.2-bin-hadoop3/python/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clients_pdf = ps.read_csv('clients.csv', names=clients_schema, header=0)"
      ],
      "metadata": {
        "id": "JT6o5V7_7THu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d821d56-3e60-4b97-a781-1ba820d09bcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/spark-3.5.2-bin-hadoop3/python/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `read_csv`, the default index is attached which can cause additional overhead.\n",
            "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clients_pdf.dtypes"
      ],
      "metadata": {
        "id": "b6daEk7D8f65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "76e844b6-d0d2-43da-8c23-0da384101d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "city          object\n",
              "client_id     object\n",
              "cnae_id       object\n",
              "cod_city       int32\n",
              "cod_tract      int64\n",
              "cod_uf         int32\n",
              "state         object\n",
              "client        object\n",
              "company_id     int32\n",
              "dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>city</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>client_id</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cnae_id</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cod_city</th>\n",
              "      <td>int32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cod_tract</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cod_uf</th>\n",
              "      <td>int32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>state</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>client</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>company_id</th>\n",
              "      <td>int32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vendas_pdf = ps.read_csv(\"vendas.csv\", names=vendas_schema, header=0)"
      ],
      "metadata": {
        "id": "MlXh5Q9_6wkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vendas_pdf.dtypes"
      ],
      "metadata": {
        "id": "4unpRqVW8W8A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "e5cf1f23-c326-4f8e-d0c3-dd100419ef12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "client_id       object\n",
              "items_count      int32\n",
              "list_price     float32\n",
              "order_date      object\n",
              "order_id         int32\n",
              "product_id      object\n",
              "sale_price     float32\n",
              "salesman_id     object\n",
              "supplier_id     object\n",
              "company_id       int32\n",
              "product         object\n",
              "salesman        object\n",
              "supplier        object\n",
              "client          object\n",
              "dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>client_id</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>items_count</th>\n",
              "      <td>int32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>list_price</th>\n",
              "      <td>float32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_date</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_id</th>\n",
              "      <td>int32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>product_id</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sale_price</th>\n",
              "      <td>float32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>salesman_id</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>supplier_id</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>company_id</th>\n",
              "      <td>int32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>product</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>salesman</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>supplier</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>client</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Camadas da Arquitetura Medallion"
      ],
      "metadata": {
        "id": "50S6eMBa59UJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bronze (Dados Brutos):\n",
        "\n",
        "* Carregar os arquivos CSV vendas.csv e clientes.csv como DataFrames Spark.\n",
        "* Criar tabelas brutas na camada Bronze, armazenando os dados brutos sem alterações."
      ],
      "metadata": {
        "id": "fBYUxhWilqYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sessão Spark\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Arquitetura Medallion\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "LgXDbB7FlsNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clients.csv bruto\n",
        "clientes_df = ps.read_csv(\"clients.csv\", header=0)\n",
        "# vendas.csv bruto\n",
        "vendas_df = ps.read_csv(\"vendas.csv\", header=0)"
      ],
      "metadata": {
        "id": "7AreATjLosS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(clientes_df.shape)\n",
        "print(vendas_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ufn4ZRKjpONR",
        "outputId": "2ac153f4-6488-4a62-82dd-f142f3f1ea35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(600750, 9)\n",
            "(349828, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`muitas duplicadas` na chave primaria o que resultou em varias combinacoes aumentando de mais esse shape dos join"
      ],
      "metadata": {
        "id": "XAIf_6Oorbp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# salvar as tabelas brutas na camada/pasta Bronze\n",
        "clientes_df.to_spark().write.option(\"header\", True).mode(\"overwrite\").csv(\"bronze/clients.csv\")\n",
        "vendas_df.to_spark().write.option(\"header\", True).mode(\"overwrite\").csv(\"bronze/vendas.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTLyYoqMo8wP",
        "outputId": "5c57ea0a-c316-4151-9471-dc4a68789e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/spark-3.5.2-bin-hadoop3/python/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_spark`, the existing index is lost when converting to Spark DataFrame.\n",
            "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
          ]
        }
      ]
    }
  ]
}