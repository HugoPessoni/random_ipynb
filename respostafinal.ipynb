{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Compare as melhores performances obtidas com as MLPs e as melhores obtidas com o k-NN. Quais as vantagens e desvantagens de cada algoritmo para os datasets explorados? Se tivesse que escolher um dos dois algoritmos, qual seu time escolheria?\n",
        "\n",
        "**Resposta:**\n",
        "\n",
        " Primeiro ponto que toda a equipe concorda, a complexida na implementação dos algoritmos, o KNN foi relativamente facil de estudar apenas utilizando a biblioteca do Sckit-learn conseguimos resolver o problema e obter uma performance muito boa utilizando o KNN. Inclusive não precisariamos da biblioteca do Sckit-learn pois a distancia euclidiana é de facil implementação até mesmo manualmente.\n",
        "\n",
        "  Já no lado da MLP todos da equipe concordam que é de extrema dificuldade a implementação dessa rede (ainda mais de forma mais manual), todos nós ficamos boas horas e levamos alguns dias para conseguir montar a rede da forma correta e sem bugs (aparentemente).\n",
        "\n",
        "---\n",
        "Vale lembrar tambem que estamos com os seguintes parametros iniciais:\n",
        "\n",
        "N = 400               numero total de amostras do dataset\n",
        "\n",
        "NOISE = 20.            intensidade do ruido de coleta no dataset\n",
        "\n",
        "SPLIT_RATIO = 0.5      porcentagem de dados usados no dataset de treino\n",
        "\n",
        "BATCH_SIZE = 10        tamanho do batch usado durante o treinamento\n",
        "\n",
        "LEARNING_RATE = 0.03   taxa de aprendizado\n",
        "\n",
        "---\n",
        "\n",
        "*   Obtivemos as seguintes acurácias:\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "| Dataset | MLP Acurácia | k-NN Acurácia |\n",
        "|:-------:|:------------:|:-------------:|\n",
        "| Spiral  | 95%          | 98,4%         |\n",
        "| Gauss   | 88%          | 99,5%         |\n",
        "| Circle  | 92%          | 100%          |\n",
        "| XOR     | 97%          | 96,9%         |\n",
        "\n",
        "<br>\n",
        "\n",
        "É importante lembrar que esses resultados foram obtidos utilizando os seguintes parâmetros no **M**ulti**L**ayer **P**erceptron (**MLP**):\n",
        "\n",
        "- **Número de Camadas de Entrada:** 2\n",
        "- **Hidden Layers:** 2\n",
        "- **Perceptrons / Layers:** 2\n",
        "- **Saídas:** 1\n",
        "- **Função de Ativação:** ReLU\n",
        "- **Loss:** Cross-Entropy\n",
        "\n",
        "<br>\n",
        "\n",
        "E para o nosso **k**-**N**earest **N**eighbors (**k-NN**) achamos o melhor valor para K sendo:\n",
        "<br>\n",
        "\n",
        "| Dataset | Melhor valor de K |\n",
        "|:-------:|:-----------------:|\n",
        "| Spiral  |         1         |\n",
        "| Gauss   |         1         |\n",
        "| Circle  |         7         |\n",
        "| XOR     |         49        |\n",
        "\n",
        "<br>\n",
        "\n",
        "Após analisar os resultados obtidos e os insights que podemos tirar são:\n",
        "\n",
        "\n",
        "**MLP VANTAGENS:**\n",
        "\n",
        "\n",
        "*   Flexibilidade de Arquitetura: Possibilidade de ajustar a arquitetura (número de camadas, neurônios por camada) conforme necessário.\n",
        "\n",
        "*   Item da lista\n",
        "\n",
        "\n",
        "**MLP DESVANTAGENS:**\n",
        "\n",
        "*   Necessidade de Treinamento: Requer um processo de treinamento mais longo e intensivo em recursos.\n",
        "\n",
        "\n",
        "*   Sensibilidade a Hiperparâmetros: A performance é sensível a escolha de hiperparâmetros como taxa de aprendizado (learningrate), número de camadas, função de ativação.\n",
        "\n",
        "\n",
        "*   Item da lista\n",
        "\n",
        "---\n",
        "**KNN VANTAGENS:**\n",
        "*   Simplicidade de Implementação: Fácil de implementar e entender.\n",
        "*   Facilidade dos parametros: Basicamente o mais relevante é o K e não precisa de muitos ajustes.\n",
        "*   Boa performance: Para os Dataset envolvidos nesse desafio o algoritmo se saiu bem.\n",
        "*   Item da lista\n",
        "\n",
        "**KNN DESVANTAGENS:**\n",
        "*   Algoritmo baseado na distancia: Só existe essa possibilidade para separar os dados, apenas as distancias entre eles, o que faz com que se fixe a um unico metodo e não abrindo brecha para outras abordagens.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k5AmcY0EuhOF"
      }
    }
  ]
}