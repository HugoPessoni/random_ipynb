{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzeNJz4m0pgH"
   },
   "source": [
    "# INF0413 - Processamento Digital de Sinais e Imagens\n",
    "A02 - Segunda avaliação da aprendizagem\n",
    "\n",
    "**Lecturer / Examiner**:\n",
    "\n",
    "Aldo Díaz (aldo.diaz@ufg.br)\n",
    "\n",
    "**Teaching Assistants:**\n",
    "\n",
    "- Gabriel Van Der Schmidt (gabriel_schmidt@discente.ufg.br)\n",
    "\n",
    "- Lucca Emmanuel Pineli Simões (lucca.pineli@discente.ufg.br)\n",
    "\n",
    "- Lucas Simões Passos (lucas.simoes@discente.ufg.br)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdnYvstuSVC5"
   },
   "source": [
    "## Introdução\n",
    "\n",
    "A classificação de sinais acústicos é uma capacidade cognitiva que nós, enquanto humanos, realizamos de forma *natural* e em todo instante de tempo (será que alguem pode escolher desligar ela?).\n",
    "Noentanto, trata-se de uma *tarefa complexa* para as máquinas devido à grande diversidade e complexidade desses sinais ao serem tratados com técnicas de processamento de sinais como dados em arquivos de áudio.\n",
    "\n",
    "O [Environmental Sound Classification 50 (ESC50)](https://www.kaggle.com/datasets/mmoreaux/environmental-sound-classification-50/) é um dataset anotado com 2000 amostras de som ambiente de várias fontes, mirado no uso como benchmark de métodos de classificação.\n",
    "\n",
    "| | | | |\n",
    "|:-------------------------:|:-------------------------:|:-------------------------:|:-------------------------:|\n",
    "|<img height=\"250\" width=\"250\" alt=\"\" src=\"https://yt3.googleusercontent.com/eY3K4zuKBcGxymSbuxwYHEn6vPt_Az3G9SUImKetmcGe8mbh75rbHGXg4xE8ojVJtatz7d0RPQw=s176-c-k-c0x00ffffff-no-rj\"> | <img height=\"250\" width=\"250\" alt=\"\" src=\"https://www.meloteca.com/wp-content/uploads/2018/11/tecnica-vocal-300x300.jpg\"> | <img height=\"250\" width=\"250\" alt=\"\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/25/Chainsaw.JPG/220px-Chainsaw.JPG\"> | <img height=\"250\" width=\"250\" alt=\"\" src=\"https://aviationvoice.com/wp-content/uploads/2017/03/Increasing-your-helicopters%E2%80%99-efficiency-mission-impossible.jpg\">\n",
    "\n",
    "É composto por 2000 clips de 5 segundos cada, uniformemente distribuídas ao longo de 50 classes incluindo sons de origem humana, doméstica e natural. Para simplicar o seu trabalho, utilizaremos um subset (ESC-10) contendo apenas 10 classes, 400 amostras ao todo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gDk-3kTSQrA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uTlQOVEitXI"
   },
   "source": [
    "**Baixe e confira o dataset antes de começar a prova!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar biblioteca auxiliar\n",
    "!pip install gdown keras tensorflow visualkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "87WRrDyjOsrd"
   },
   "outputs": [],
   "source": [
    "# Baixar os arquivos\n",
    "!gdown 1LtZf0J7mUzDjIeT57IcpqtVQmzqAMgYF\n",
    "!gzip -dc 'esc50.tar.gz' | tar xvf -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "krDkELB7HqR2"
   },
   "outputs": [],
   "source": [
    "root = '.' # '/content'\n",
    "esc50 = pd.read_csv(os.path.join(root, 'esc50.csv'))\n",
    "\n",
    "print(esc50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MYH_qBPsQA-q"
   },
   "outputs": [],
   "source": [
    "# Selecionar apenas as amostras que pertencem ao dataset ESC10\n",
    "esc10 = esc50.query('esc10 == True')\n",
    "\n",
    "print(esc10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGJ96A51RiHl"
   },
   "outputs": [],
   "source": [
    "files = np.array(esc10['filename'])\n",
    "y     = np.array(esc10['target'])\n",
    "\n",
    "print(files[:20])\n",
    "print(y[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_0yg3seUV0b"
   },
   "outputs": [],
   "source": [
    "# Carregar arquivos de áudio\n",
    "# Conferir que todos tenham 5 segundos de duração e fs=16kHz\n",
    "fs = 16000\n",
    "X = []\n",
    "k = 1\n",
    "for file in files:\n",
    "    filename = os.path.join(root, 'esc50', file)\n",
    "    if not os.path.isfile(filename):\n",
    "        print(f'ERROR: File {filename} not found!')\n",
    "        break\n",
    "    fs_tmp, signal = wavfile.read(filename)\n",
    "    print(f'{k} - Read file {file}.')\n",
    "    k += 1\n",
    "    if fs != fs_tmp:\n",
    "        print(f'ERROR: File {filename} has fs different than expected. Expected {fs}, got {fs_tmp}!')\n",
    "        break\n",
    "    X.append(signal)\n",
    "\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNhCmMOyW5JT"
   },
   "outputs": [],
   "source": [
    "# Checar que todos os sinais tenham a mesma dimensão\n",
    "signal_lens = [len(signal) for signal in X]\n",
    "\n",
    "print(np.unique(signal_lens)) # Sim!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZ9HXtBVXRlF"
   },
   "outputs": [],
   "source": [
    "# E então converter para um array numpy\n",
    "X = np.array(X)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dqTPEUEVaEmE"
   },
   "outputs": [],
   "source": [
    "# Dicas/Funções úteis - parte 1\n",
    "\n",
    "# Obter STFT e plotar\n",
    "def STFT(sinal, tamanho_janela=256, tamanho_passo=128):\n",
    "    '''\n",
    "        Calcula a STFT de um sinal.\n",
    "        Parâmetros:\n",
    "        - sinal: np.array\n",
    "            O sinal de entrada.\n",
    "        - tamanho_janela: int\n",
    "            Tamanho da janela para cada segmento.\n",
    "        - tamanho_passo: int\n",
    "            Número de amostras entre frames sucessivos.\n",
    "        Retorna:\n",
    "        - matriz_stft: np.array\n",
    "            Matriz contendo os coeficientes STFT.\n",
    "    '''\n",
    "    num_amostras = len(sinal)\n",
    "    num_janelas  = 1 + (num_amostras - tamanho_janela) // tamanho_passo\n",
    "\n",
    "    # Prepara a função de janela (janela de Hann neste caso)\n",
    "    janela = np.hanning(tamanho_janela)\n",
    "\n",
    "    # Inicializa a matriz STFT\n",
    "    matriz_stft = np.zeros((num_janelas, tamanho_janela // 2 + 1), \\\n",
    "                           dtype=np.complex128)\n",
    "\n",
    "    # Calcula a STFT\n",
    "    for k in range(num_janelas):\n",
    "        inicio = k * tamanho_passo\n",
    "        fim = inicio + tamanho_janela\n",
    "        segmento = sinal[inicio:fim]\n",
    "\n",
    "        # Aplica a função de janela\n",
    "        segmento_janelado = segmento * janela\n",
    "\n",
    "        # Calcula a FFT\n",
    "        resultado_fft = np.fft.fft(segmento_janelado)\n",
    "\n",
    "        # Armazena apenas as frequências não negativas (até a frequência de Nyquist)\n",
    "        matriz_stft[k, :] = resultado_fft[:tamanho_janela // 2 + 1]\n",
    "\n",
    "    return abs(matriz_stft)\n",
    "\n",
    "\n",
    "def plot_spectrogram(sinal, fs, tamanho_janela=256, tamanho_passo=128):\n",
    "    # Calcular espectrograma\n",
    "    spec_signal = STFT(sinal, \\\n",
    "                       tamanho_janela=tamanho_janela, \\\n",
    "                       tamanho_passo=tamanho_passo)\n",
    "\n",
    "    # Calcular shape do plot\n",
    "    stft_signal_shape = spec_signal.T.shape\n",
    "    print(stft_signal_shape)\n",
    "\n",
    "    # Determinar tempo do audio e frequência máxima\n",
    "    audio_duration = len(sinal)/fs\n",
    "    window_size = (stft_signal_shape[0] - 1)*2\n",
    "    max_freq = np.fft.fftfreq(window_size, 1 / fs)[window_size// 2 - 1]\n",
    "\n",
    "    # Determinar eixos de tempo e frequencia\n",
    "    time_values = np.linspace(0, audio_duration, stft_signal_shape[1])\n",
    "    frequency_values = np.linspace(0, max_freq, stft_signal_shape[0])\n",
    "\n",
    "    # Criar mapa\n",
    "    heatmap = sns.heatmap(spec_signal.T, cmap = 'viridis')\n",
    "\n",
    "    # Inverter o mapa\n",
    "    heatmap.invert_yaxis()\n",
    "\n",
    "    # Adicione rótulos aos eixos\n",
    "    plt.title('Espectrograma do Sinal')\n",
    "    plt.ylabel('Frequência (Hz)')\n",
    "    plt.xlabel('Tempo (s)')\n",
    "\n",
    "    # Setar eixos\n",
    "    plt.xticks(np.arange(0, stft_signal_shape[1], step=stft_signal_shape[1] // 8), \\\n",
    "               labels=np.around(time_values[::stft_signal_shape[1] // 8], decimals=2), \\\n",
    "               rotation=45)\n",
    "    plt.yticks(np.arange(0, stft_signal_shape[0], step=stft_signal_shape[0] // 8), \\\n",
    "               labels=np.around(frequency_values[::stft_signal_shape[0] // 8], decimals=2))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pnjADHHkENBn"
   },
   "outputs": [],
   "source": [
    "# Dicas/Funções úteis - parte 2\n",
    "# (não rode esta célula, apenas copie, cole e edite onde você precisar)\n",
    "\n",
    "# Plotar FFT\n",
    "fft = np.abs(np.fft.fft(signal))\n",
    "plt.stem(fft, 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOitu1ic0kkQ"
   },
   "source": [
    "## Questão 1: (1,5 pontos)\n",
    "\n",
    "- Obtenha e visualize o espectrograma de duas amostras de classes diferentes.\n",
    "\n",
    "- Compare o gráfico dos respectivos sinais de áudio originais com o gráfico do espectro (magnitude da DFT).\n",
    "\n",
    "- Quais as vantagens ou desvantagens de usar um ou outro e por quê (áudio bruto vs DFT vs espectrograma)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cEC11iKgrtmd"
   },
   "outputs": [],
   "source": [
    "# Seu código aqui, lembre-se de comentar seus resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NoKj1CWt3rcJ"
   },
   "source": [
    "## Questão 2: (1,5 pontos)\n",
    "\n",
    "Varie os valores dos parâmetros `tamanho_janela` (*default=256*) e `tamanho_passo` (*default=128*) na função geradora da transformada de Fourier de tempo curto (STFT).\n",
    "\n",
    "- Como eles alteram a imagem do espectrograma resultante?\n",
    "\n",
    "- Quais os possíveis usos/vantagens/desvantagens de alterar esses valores?\n",
    "\n",
    "**Dica 1:**\n",
    "Plote os resultados e observe os shapes das saídas.\n",
    "Procure espectrogramas com respostas mais vibrantes para as mudanças ficarem mais óbvias.\n",
    "\n",
    "**Dica 2:** A primeira dimensão de `STFT` corresponde às frequências, e a segunda corresponde ao tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7l81-AZjrmzc"
   },
   "outputs": [],
   "source": [
    "# Seu código aqui, lembre-se de comentar seus resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FX8u2arO6Nqd"
   },
   "source": [
    "## Questão 3: (5,5 pontos)\n",
    "\n",
    "- Transforme os sinais de áudio em espectrogramas com valores de `tamanho_janela` e `tamanho_passo` de sua escolha.\n",
    "Aproveite as conclusões da questão anterior e os resultados obtidos pelo modelo para escolher esses valores.\n",
    "\n",
    "- Aplique métodos de pré-processamento (*e.g.*, redução de dimensionalidade) conforme for razoável.\n",
    "Use o desempenho do modelo como guia.\n",
    "\n",
    "- Treine um ***modelo de Regressão Logística*** com hiperparâmetros *default*.\n",
    "Use uma divisão de treino e teste conforme a célula de código a seguir.\n",
    "Avalie o desempenho de sua abordagem.\n",
    "\n",
    "- Tente refinar sua abordagem com base na avaliação do modelo original.\n",
    "Quais os impactos das mudanças feitas?\n",
    "\n",
    "**Dica 1:** Para métodos de pré-processamento ou redução de dimensionalidade, use `fit`/`fit_transform` no conjunto de treino, mas apenas `transform` no conjunto de teste!\n",
    "\n",
    "**Dica 2:** Métodos de normalização ou padronização da biblioteca `sklearn` normalizam \"*coluna-a-coluna*\" (feature-a-feature).\n",
    "Como cada espectrograma possui uma amplitude diferente dos demais, o melhor aqui é normalizar \"*amostra-a-amostra*\".\n",
    "\n",
    "**Dica 3:** `LogisticRegression` espera um array 2D de entrada de dimensões (`n_samples`, `n_features`).\n",
    "Mas, o dataset de espectrogramas será 3D (`n_samples`, `spec_height`, `spec_width`).\n",
    "Nesse caso, faça um \"*reshape*\" do array.\n",
    "\n",
    "**Dica 4:** Mantenha seus testes organizados e ordenados.\n",
    "\n",
    "**Dica 5:** Comente suas decisões, achados e conclusões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvQ_4nrlunA2"
   },
   "outputs": [],
   "source": [
    "# Gerar espectrograma para cada sinal e concatenar em um único array numpy\n",
    "X_spec = ... # Seu código aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjNXuMRfu8wO"
   },
   "outputs": [],
   "source": [
    "# WARNING!: NÃO MUDE O CONTEÚDO DESTA CÉLULA\n",
    "\n",
    "# Depois de gerar o dataset de espetrogramas, dividir em sets de treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# O parametro `stratify` garante que as distribuições das classes nos sets de\n",
    "# treino/teste serão o mais próximas possível da distribuição original do\n",
    "# dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_spec, \\\n",
    "                                                    y, \\\n",
    "                                                    test_size=0.25, \\\n",
    "                                                    random_state=42, \\\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VDKJr9oaw5yB"
   },
   "outputs": [],
   "source": [
    "# Pre-processamento...\n",
    "# Sugestões: sklearn.preprocessing.StandardScaler,\n",
    "#            sklearn.preprocessing.MinMaxScaler,\n",
    "#            sklearn.decomposition.PCA,\n",
    "#            etc ...\n",
    "\n",
    "# Seu código aqui..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQIfC560ChbF"
   },
   "outputs": [],
   "source": [
    "# Definição do modelo\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jAe6l2lHyAxu"
   },
   "outputs": [],
   "source": [
    "# Treino do modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LC8ugDnTzITu"
   },
   "outputs": [],
   "source": [
    "# Avaliação do modelo\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report_dict = classification_report(y_test, y_hat, output_dict=True)\n",
    "\n",
    "print(report_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-VvNLf0SzTNx"
   },
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrIvM71K_rO0"
   },
   "source": [
    "## Convolução: Uma potente ferramenta no processamento de sinais\n",
    "\n",
    "Já que estamos trabalhando com espectrogramas e, como agora sabemos, espectrogramas são imagens, vamos introduzir brevemente uma técnica de processamento de sinais e imagens:\n",
    "a famosa ***convolução***!\n",
    "\n",
    "Em termos simples, a convolução de um sinal $x$ por outro sinal $y$ (chamado de kernel, máscara, ou janela) é o processo de **deslizar $y$ ao longo de $x$** e, em cada posição, fazer a **soma ponderada** dos elementos sobrepostos de $x$ e $y$ (os valores de $y$ são usados como pesos dessa ponderação).\n",
    "Este processo gera um novo sinal $z$ que é dito de convolução."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9rgaKGPaP_R"
   },
   "source": [
    "<img src=\"https://www.researchgate.net/profile/Vincenzo-Randazzo/publication/346433900/figure/fig2/AS:962790265217050@1606558495822/Example-of-1D-Convolution-Neural-Network.jpg\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "Na imagem acima:\n",
    "- o primeiro vetor é o sinal $x$,\n",
    "- os pesos $w_1$, $w_2$ e $w_3$ formam $y$,\n",
    "- o vetor final é $z$, gerado pela convolução de $x$ e $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMlznEUOaPjo"
   },
   "source": [
    "Como os sinais que estudamos até agora são vetores 1D, podemos extrapolar e pensar em **imagens como sinais 2D**!\n",
    "Isso significa que podemos generalizar algumas técnicas de PDS de sinais 1D para sinais 2D.\n",
    "\n",
    "No caso da convolução, ao invés de deslizar um vetor 1D sobre um outro, podemos deslizar uma matriz 2D (uma imagem, em nosso caso, um espectrograma!) sobre uma segunda matriz 2D (um kernel de convolução).\n",
    "De novo, o resultado depende do kernel que escolhermos, sendo ele utilisado para tarefas como importantes, tais como a detecção de bordas, remoção de ruídos, suavização da imagem, etc.\n",
    "\n",
    "Convoluções possuem diversas aplicações pois, mudando o tamanho e os valores da máscara, podemos obter resultados de processamento diferentes (os quais estudaremos na próxima unidade da disciplina)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgUngg7-dZwd"
   },
   "source": [
    "<img src=\"https://miro.medium.com/v2/resize:fit:640/format:webp/1*1okwhewf5KCtIPaFib4XaA.gif\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "Esse é o GIF de um [artigo bem bacana](https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1) que representa esse processo de \"*deslizar*\" uma matriz sobre a outra durante a convolução.\n",
    "Aqui a matriz azul é a imagem original, a zona sobreada é o kernel sobreposto, e a matriz verde (azul esverdeado?) é a imagem resultante do processo de convolução.\n",
    "\n",
    "### A escolha do kernel\n",
    "\n",
    "Mas então, **como** que encontramos um \"*bom kernel*\"?\n",
    "\n",
    "- Força bruta _ad aeternum_?\n",
    "\n",
    "- Copiar e colar de trabalhos existentes?\n",
    "\n",
    "Quem dera houvesse um algoritmo que ***automaticamente*** escolhesse pesos ótimos para esse kernel de acordo com a nossa necessidade, não é?\n",
    "\n",
    "Pois bem, apresentamos para vocês as ***Redes Neurais Convolucionais*** (Convolutional Neural Networks - CNNs)!\n",
    "\n",
    "### CNN\n",
    "\n",
    "Uma CNN é uma rede neural que realiza várias convoluções e otimiza os valores dos kernels seguindo o gradiente descendente (backpropagation).\n",
    "Esta é uma técnica perfeita para o processamento de imagens, pois \"*extraimos informações*\" da imagem, mas \"*mantendo a sua disposição espacial*\"!\n",
    "\n",
    "Não se preocupe em entender tudo sobre CNNs agora, teremos tempo para isso no futuro.\n",
    "O que importa agora é brincar um pouco com essa nova ferramenta e ver o que conseguimos fazer com ela."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sunjKPLSXEA6"
   },
   "source": [
    "## Questão 4: (1,5 pontos)\n",
    "\n",
    "Crie um novo dataset de espectrogramas, como o feito na questão 3, com parâmetros default.\n",
    "\n",
    "Treine e avalie o desempenho da CNN abaixo.\n",
    "\n",
    "O resultado foi melhor ou pior que a sua abordagem na questão 3? Por que você acha que esse foi o caso?\n",
    "\n",
    "- **Dica 1:** Essa CNN toma como entrada imagens 2D.\n",
    "Não passe arrays 1D para ela.\n",
    "\n",
    "- **Dica 2:** Use os valores default de `tamanho_janela` e `tamanho_passo` (256 e 128, respectivamente) nos espectrogramas utilisados para o treino da CNN, pois você precisará mudar o tamanho da entrada da rede (`input_size`) caso você use outros valores.\n",
    "\n",
    "- **Dica 3:** Use os mesmos valores dos argumentos de `train_test_split` usados acima.\n",
    "\n",
    "- **Dica 4:** Se o treinamento da rede estiver demorando muito, usar um ambiente com GPU vai acelerar o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "MnPXR064yLR6"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Activation, Conv2D, Dense, Dropout, Flatten, Input, MaxPool2D\n",
    "import visualkeras\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fD7aJZNQR5iF"
   },
   "outputs": [],
   "source": [
    "# Gerar novo dataset de espectrogramas\n",
    "X_spec = ... # Seu código aqui\n",
    "\n",
    "# Para a CNN, `y` deve ser one-hot encoded\n",
    "encoder = OneHotEncoder()\n",
    "y_one_hot = encoder.fit_transform(y.reshape(-1, 1)).todense()\n",
    "\n",
    "# Dividir em sets de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_spec, \\\n",
    "                                                    y_one_hot, \\\n",
    "                                                    test_size=0.25, \\\n",
    "                                                    random_state=42, \\\n",
    "                                                    stratify=y)\n",
    "\n",
    "# Você pode normalizar os dados se quiser\n",
    "# mas NÃO aplique redução de dimensionalidade nas imagens\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1omDdNIDXWp"
   },
   "outputs": [],
   "source": [
    "# Definição de rede CNN pronta para treinar\n",
    "def build_model(input_size=(624, 129, 1), \\\n",
    "                n_classes=10, \\\n",
    "                conv_layers=(8, 16, 32), \\\n",
    "                ksize=5, \\\n",
    "                maxpool_size=3, \\\n",
    "                dense_layers=(32,), \\\n",
    "                dropout_rate=0.5, \\\n",
    "                conv_activation='relu', \\\n",
    "                dense_activation='sigmoid'):\n",
    "\n",
    "    inputs = Input(shape=input_size)\n",
    "    x      = inputs\n",
    "\n",
    "    # Camadas convolucionais + camadas extras para melhorar o desempenho da rede\n",
    "    for filters in conv_layers:\n",
    "        x = Conv2D(filters=filters, kernel_size=ksize, padding='valid')(x)\n",
    "        x = Activation(conv_activation)(x)\n",
    "        x = MaxPool2D(pool_size=maxpool_size)(x)\n",
    "        x = Dropout(rate=dropout_rate)(x)\n",
    "\n",
    "    # Camadas densas\n",
    "    x = Flatten()(x) # \"Amassar\" o array 2D em um array 1D\n",
    "    for neurons in dense_layers:\n",
    "        x = Dense(units=neurons, activation=dense_activation)(x)\n",
    "\n",
    "    # Camada final, cada neurônio corresponde a uma classe\n",
    "    outputs = Dense(units=n_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, \\\n",
    "                  outputs=outputs, \\\n",
    "                  name='CNN_spectrograms_1')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMACVk3CLsjI"
   },
   "outputs": [],
   "source": [
    "# Definir seed para resultados reproduzíveis\n",
    "keras.utils.set_random_seed(42)\n",
    "\n",
    "# Construir modelo com parâmetros default\n",
    "model      = build_model()\n",
    "learn_rate = 1e-3 # 0.001\n",
    "opt        = Adam(learning_rate=learn_rate)\n",
    "model.compile(loss = 'categorical_crossentropy', \\\n",
    "              optimizer = opt, \\\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IbdPZo9rMGXn"
   },
   "outputs": [],
   "source": [
    "# Visualizar modelo - parte 1\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bajFUx2MJXW"
   },
   "outputs": [],
   "source": [
    "# Visualizar modelo - parte 2\n",
    "visualkeras.layered_view(model, \\\n",
    "                         legend=True, \\\n",
    "                         draw_volume=True, \\\n",
    "                         scale_xy=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UYqX2F-3MroV"
   },
   "outputs": [],
   "source": [
    "# Treino\n",
    "history = model.fit(X_train, \\\n",
    "                    y_train, \\\n",
    "                    validation_split=0.2, \\\n",
    "                    epochs=70, \\\n",
    "                    verbose=1)\n",
    "# Partição de validação para acompanharmos o\n",
    "# desempenho \"real\" da rede ao longo do treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aYsXMDuXUOwt"
   },
   "outputs": [],
   "source": [
    "# Plotar curvas de loss\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k0h3-rkJUXaG"
   },
   "outputs": [],
   "source": [
    "# Plotar curvas de acurácia\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hHzGoMMBq3Nc"
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "y_hat = encoder.inverse_transform(y_hat).reshape(-1)\n",
    "y_test2 = encoder.inverse_transform(np.asarray(y_test)).reshape(-1)\n",
    "\n",
    "print(y_hat.shape)\n",
    "print(y_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6On8PmYgPsp"
   },
   "outputs": [],
   "source": [
    "# Avaliar o modelo\n",
    "report_dict = classification_report(y_test2, y_hat, output_dict=True)\n",
    "\n",
    "print(report_dict)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
